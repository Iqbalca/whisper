{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Whisper is a speech recognition model by Open AI that can understand multiple languages\n",
    "- It has been trained on 680,000 hours of supervised data collected from the web\n",
    "- It combines different open-source Speech-to-text models that are already available like Kaldi, wav2vec 2.0 and other\n",
    "- It matches the state-of-the-art results for speech recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Whisper paper compares the accuracy of the model by using Word-Error-Rate (WER), to current state-of-the-art speech recognition models. \n",
    "Whisper reports achieving state-of-the-art results\n",
    "\n",
    "![datasets](paper-result.png \"Evaluation of the models on different datasets\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below figure reports Whisper's Word-Error-Rates for each supported language.\n",
    "Whisper achieves state-of-the-art results on several languages, German, Japanese, and more\n",
    "\n",
    "\n",
    "![datasets](multilingual_wer.png \"Evaluation of the models on different datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Inference Time\n",
    "\n",
    "- This model is available in five sizes - tiny, base, small, medium, and large \n",
    "- The model gets more and more accuracy with the size\n",
    "- The large model has the best accuracy and used in benchmarks reported in the paper\n",
    "- It can be used on both CPU and GPU\n",
    "- Inference time is slow on CPU when we use the large size models and so it is sugegsted to run only on GPU\n",
    "\n",
    "The Comparison results on CPU (i5-11300H) and GPU (high RAM GPU Colab environment)\n",
    "\n",
    "![datasets](WHisper-Inference-Time-2.png \"Evaluation of the models on different datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also immediately test out how Whisper transcribes speech to text on HuggingFace spaces here.\n",
    "\n",
    "1. Base [Model](https://huggingface.co/spaces/iqbalc/openAI-base)\n",
    "2. Large [Model](https://huggingface.co/spaces/iqbalc/Speech-to-text-demo) \n",
    "\n",
    "Just make sure you can use your microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://cdn.openai.com/papers/whisper.pdf\n",
    "2. https://openai.com/blog/whisper/\n",
    "3. https://github.com/openai/whisper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1840497608826e95edb9ca3288ed76e181d972ed8c044b13b4557a573be3002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
